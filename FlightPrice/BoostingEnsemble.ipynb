{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BoostingEnsembleAverage",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "PaFnbqn3672t",
        "sRAp5gUC7DRp",
        "MFguRo-i9ET2",
        "ZyHP-Qz4795h",
        "LapmourD6tbr",
        "uMaSD2jP7u57",
        "-M7GoWdd7IRC",
        "H2BuCDsyDcxR",
        "scJq7Gv5X1dC",
        "6mjCnD3Z7PrS",
        "Nmf8OqYUpwMD",
        "QU7-V0NvLIc_",
        "2lBcWgj8n_wU",
        "B_oq1ftJL4zX"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "jbPbxS7j7ldq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Import"
      ]
    },
    {
      "metadata": {
        "id": "vU0OsVfsNXot",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!pip install sklearn_pandas"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JPwp5ATyGrIz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Without stop split and stacking**\n",
        "\n",
        "~~One entry of Trujet - replace with SpiceJet~~  \n",
        "JA = 80,000 , JAB = 50,000 & SJ = 25000(5136), looks like outliers  \n",
        "~~After weekday add month as well~~  \n",
        "~~Should we mark all above 50000 from JA as JAB?~~  \n",
        "~~Stratefy based on price bins, Airline, Months~~  \n",
        "End date on Sat or Sun  \n",
        "~~Duration is long or short~~ bad may be tune durationTime \n",
        "\n",
        "KNN, SVR, Ada,light,gbm  \n",
        "Excess time in flight.\n"
      ]
    },
    {
      "metadata": {
        "id": "_NjpPwgJorn3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def temp_to_min(X):\n",
        "    hour, minute = pd.Series(X).str.split(\" \", 1).str\n",
        "    hour = pd.Series(hour).str.replace(\"h\", \" \")\n",
        "    hour = hour.astype('int64')\n",
        "    minute = pd.Series(minute).str.replace(\"m\", \" \")\n",
        "    minute = minute.fillna(0)\n",
        "    minute = minute.astype('int64')\n",
        "    total_minute = pd.to_timedelta( (hour * 60) + minute, unit = \"m\" )\n",
        "    return(total_minute)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PaFnbqn3672t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Load modules"
      ]
    },
    {
      "metadata": {
        "id": "GI053nEcEEFn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn_pandas import DataFrameMapper, FunctionTransformer, CategoricalImputer\n",
        "from sklearn.preprocessing import LabelEncoder, LabelBinarizer, KBinsDiscretizer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.base import TransformerMixin\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bylysnf0ERxD",
        "colab_type": "code",
        "outputId": "93f4b055-953b-42ba-b653-097b4899de5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pIgI_vC6wsPf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Data Cleaning"
      ]
    },
    {
      "metadata": {
        "id": "P-EU7e1WEdB7",
        "colab_type": "code",
        "outputId": "304340d2-866f-4cdc-9825-f5f47843b942",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        }
      },
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv(\"drive/My Drive/PyColab Work/FlightPricePredict/train.csv\")\n",
        "sub_data = pd.read_csv(\"drive/My Drive/PyColab Work/FlightPricePredict/test.csv\")\n",
        "#train_data.drop(index = 6474, inplace = True, axis = 0) # 5m flight time #change to 24hr 5m\n",
        "train_data.iloc[6474, 7] = \"24h 5m\"\n",
        "sub_data.iloc[2660, 7] = \"24h 5m\"\n",
        "\n",
        "train_data.iloc[1478, 0] = \"Jet Airways Business\"\n",
        "train_data.iloc[2618, 0] = \"Jet Airways Business\"\n",
        "train_data.iloc[5439, 0] = \"Jet Airways Business\"\n",
        "\n",
        "train_data.drop(index = 2924, inplace = True, axis = 0)\n",
        "#train_data.drop(index = 5136, inplace = True, axis = 0)\n",
        "#train_data.drop(index = 2618, inplace = True, axis = 0)\n",
        "#train_data.drop(index = 5439, inplace = True, axis = 0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Date need to be looked at # Move this\n",
        "train_data[\"Week\"] = pd.to_datetime(train_data[\"Date_of_Journey\"], dayfirst = True).dt.weekday_name\n",
        "train_data[\"Month\"] = pd.to_datetime(train_data[\"Date_of_Journey\"], dayfirst = True).dt.month\n",
        "train_data[\"Airline\"] = train_data.Airline.replace(\"Trujet\", \"SpiceJet\")\n",
        "train_data[\"class\"] = np.where(train_data['Airline']=='Jet Airways Business', 'High', 'Low')\n",
        "train_data[\"meal\"] = np.where(train_data['Additional_Info']=='In-flight meal not included', 'High', 'Low')\n",
        "train_data[\"checkin\"] = np.where(train_data['Additional_Info']=='No check-in baggage included', 'High', 'Low')\n",
        "train_data[\"Destination\"] = np.where(train_data[\"Destination\"] == \"New Delhi\", \"Delhi\", train_data[\"Destination\"])\n",
        "train_data[\"Airline\"] = np.where(train_data[\"Airline\"] == \"Vistara Premium economy\", \"Multiple carriers Premium economy\", train_data[\"Airline\"])\n",
        "train_data['landing'] = pd.to_datetime(train_data['Date_of_Journey'] + '-' + train_data['Dep_Time'], dayfirst = True) + temp_to_min(train_data[\"Duration\"])\n",
        "train_data[\"landingWeek\"] = pd.to_datetime(train_data[\"landing\"]).dt.weekday_name\n",
        "train_data[\"Source\"] = train_data[\"Source\"] + train_data[\"Destination\"]\n",
        "train_data.head()\n",
        "\n",
        "#Seperate y here itself"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Airline</th>\n",
              "      <th>Date_of_Journey</th>\n",
              "      <th>Source</th>\n",
              "      <th>Destination</th>\n",
              "      <th>Route</th>\n",
              "      <th>Dep_Time</th>\n",
              "      <th>Arrival_Time</th>\n",
              "      <th>Duration</th>\n",
              "      <th>Total_Stops</th>\n",
              "      <th>Additional_Info</th>\n",
              "      <th>Price</th>\n",
              "      <th>Week</th>\n",
              "      <th>Month</th>\n",
              "      <th>class</th>\n",
              "      <th>meal</th>\n",
              "      <th>checkin</th>\n",
              "      <th>landing</th>\n",
              "      <th>landingWeek</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>IndiGo</td>\n",
              "      <td>24/03/2019</td>\n",
              "      <td>BangloreDelhi</td>\n",
              "      <td>Delhi</td>\n",
              "      <td>BLR ? DEL</td>\n",
              "      <td>22:20</td>\n",
              "      <td>01:10 22 Mar</td>\n",
              "      <td>2h 50m</td>\n",
              "      <td>non-stop</td>\n",
              "      <td>No info</td>\n",
              "      <td>3897</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>3</td>\n",
              "      <td>Low</td>\n",
              "      <td>Low</td>\n",
              "      <td>Low</td>\n",
              "      <td>2019-03-25 01:10:00</td>\n",
              "      <td>Monday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Air India</td>\n",
              "      <td>1/05/2019</td>\n",
              "      <td>KolkataBanglore</td>\n",
              "      <td>Banglore</td>\n",
              "      <td>CCU ? IXR ? BBI ? BLR</td>\n",
              "      <td>05:50</td>\n",
              "      <td>13:15</td>\n",
              "      <td>7h 25m</td>\n",
              "      <td>2 stops</td>\n",
              "      <td>No info</td>\n",
              "      <td>7662</td>\n",
              "      <td>Wednesday</td>\n",
              "      <td>5</td>\n",
              "      <td>Low</td>\n",
              "      <td>Low</td>\n",
              "      <td>Low</td>\n",
              "      <td>2019-05-01 13:15:00</td>\n",
              "      <td>Wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Jet Airways</td>\n",
              "      <td>9/06/2019</td>\n",
              "      <td>DelhiCochin</td>\n",
              "      <td>Cochin</td>\n",
              "      <td>DEL ? LKO ? BOM ? COK</td>\n",
              "      <td>09:25</td>\n",
              "      <td>04:25 10 Jun</td>\n",
              "      <td>19h</td>\n",
              "      <td>2 stops</td>\n",
              "      <td>No info</td>\n",
              "      <td>13882</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>6</td>\n",
              "      <td>Low</td>\n",
              "      <td>Low</td>\n",
              "      <td>Low</td>\n",
              "      <td>2019-06-10 04:25:00</td>\n",
              "      <td>Monday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>IndiGo</td>\n",
              "      <td>12/05/2019</td>\n",
              "      <td>KolkataBanglore</td>\n",
              "      <td>Banglore</td>\n",
              "      <td>CCU ? NAG ? BLR</td>\n",
              "      <td>18:05</td>\n",
              "      <td>23:30</td>\n",
              "      <td>5h 25m</td>\n",
              "      <td>1 stop</td>\n",
              "      <td>No info</td>\n",
              "      <td>6218</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>5</td>\n",
              "      <td>Low</td>\n",
              "      <td>Low</td>\n",
              "      <td>Low</td>\n",
              "      <td>2019-05-12 23:30:00</td>\n",
              "      <td>Sunday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>IndiGo</td>\n",
              "      <td>01/03/2019</td>\n",
              "      <td>BangloreDelhi</td>\n",
              "      <td>Delhi</td>\n",
              "      <td>BLR ? NAG ? DEL</td>\n",
              "      <td>16:50</td>\n",
              "      <td>21:35</td>\n",
              "      <td>4h 45m</td>\n",
              "      <td>1 stop</td>\n",
              "      <td>No info</td>\n",
              "      <td>13302</td>\n",
              "      <td>Friday</td>\n",
              "      <td>3</td>\n",
              "      <td>Low</td>\n",
              "      <td>Low</td>\n",
              "      <td>Low</td>\n",
              "      <td>2019-03-01 21:35:00</td>\n",
              "      <td>Friday</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Airline Date_of_Journey           Source Destination  \\\n",
              "0       IndiGo      24/03/2019    BangloreDelhi       Delhi   \n",
              "1    Air India       1/05/2019  KolkataBanglore    Banglore   \n",
              "2  Jet Airways       9/06/2019      DelhiCochin      Cochin   \n",
              "3       IndiGo      12/05/2019  KolkataBanglore    Banglore   \n",
              "4       IndiGo      01/03/2019    BangloreDelhi       Delhi   \n",
              "\n",
              "                   Route Dep_Time  Arrival_Time Duration Total_Stops  \\\n",
              "0              BLR ? DEL    22:20  01:10 22 Mar   2h 50m    non-stop   \n",
              "1  CCU ? IXR ? BBI ? BLR    05:50         13:15   7h 25m     2 stops   \n",
              "2  DEL ? LKO ? BOM ? COK    09:25  04:25 10 Jun      19h     2 stops   \n",
              "3        CCU ? NAG ? BLR    18:05         23:30   5h 25m      1 stop   \n",
              "4        BLR ? NAG ? DEL    16:50         21:35   4h 45m      1 stop   \n",
              "\n",
              "  Additional_Info  Price       Week  Month class meal checkin  \\\n",
              "0         No info   3897     Sunday      3   Low  Low     Low   \n",
              "1         No info   7662  Wednesday      5   Low  Low     Low   \n",
              "2         No info  13882     Sunday      6   Low  Low     Low   \n",
              "3         No info   6218     Sunday      5   Low  Low     Low   \n",
              "4         No info  13302     Friday      3   Low  Low     Low   \n",
              "\n",
              "              landing landingWeek  \n",
              "0 2019-03-25 01:10:00      Monday  \n",
              "1 2019-05-01 13:15:00   Wednesday  \n",
              "2 2019-06-10 04:25:00      Monday  \n",
              "3 2019-05-12 23:30:00      Sunday  \n",
              "4 2019-03-01 21:35:00      Friday  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "7bUx7Eslr9EM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%script false\n",
        "\n",
        "def flight_data_clean(df) :\n",
        "  df[\"Week\"] = pd.to_datetime(df[\"Date_of_Journey\"]).dt.weekday\n",
        "  df[\"Month\"] = pd.to_datetime(df[\"Date_of_Journey\"]).dt.month\n",
        "  df = df.drop(['Date_of_Journey','Route', 'Additional_Info'], axis = 1)\n",
        "  df = pd.get_dummies(df, columns=['Airline', 'Source', 'Destination', 'Total_Stops'])\n",
        "  return(df)\n",
        "\n",
        "flight_data_clean(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FRdcAH2oslGt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sub_data[\"Week\"] = pd.to_datetime(sub_data[\"Date_of_Journey\"], dayfirst = True).dt.weekday_name\n",
        "sub_data[\"Month\"] = pd.to_datetime(sub_data[\"Date_of_Journey\"], dayfirst = True).dt.month\n",
        "sub_data[\"class\"] = np.where(sub_data['Airline']=='Jet Airways Business', 'High', 'Low')\n",
        "sub_data[\"meal\"] = np.where(sub_data['Additional_Info']=='In-flight meal not included', 'High', 'Low')\n",
        "sub_data[\"checkin\"] = np.where(sub_data['Additional_Info']=='No check-in baggage included', 'High', 'Low')\n",
        "sub_data[\"Destination\"] = np.where(sub_data[\"Destination\"] == \"New Delhi\", \"Delhi\", sub_data[\"Destination\"])\n",
        "sub_data[\"Airline\"] = np.where(sub_data[\"Airline\"] == \"Vistara Premium economy\", \"Multiple carriers Premium economy\", sub_data[\"Airline\"])\n",
        "sub_data['landing'] = pd.to_datetime(sub_data['Date_of_Journey'] + '-' + sub_data['Dep_Time'], dayfirst = True) + temp_to_min(sub_data[\"Duration\"])\n",
        "sub_data[\"landingWeek\"] = pd.to_datetime(sub_data[\"landing\"]).dt.weekday_name\n",
        "sub_data[\"Source\"] = sub_data[\"Source\"] + sub_data[\"Destination\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2D1eR-kDNddZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoder = LabelBinarizer() # LabelBinarizer()  ~~#LabelEncoder()~~\n",
        "to_bin = KBinsDiscretizer(n_bins=3, encode = 'onehot-dense')\n",
        "\n",
        "\n",
        "class to_min(TransformerMixin):\n",
        "  \n",
        "  def fit(self, X, y=None):\n",
        "    return self\n",
        "  \n",
        "  def transform(self, X):\n",
        "    hour, minute = pd.Series(X).str.split(\" \", 1).str\n",
        "    hour = pd.Series(hour).str.replace(\"h\", \" \")\n",
        "    hour = hour.astype('int64')\n",
        "    minute = pd.Series(minute).str.replace(\"m\", \" \")\n",
        "    minute = minute.fillna(0)\n",
        "    minute = minute.astype('int64')\n",
        "    total_minute = pd.Series( (hour * 60) + minute )\n",
        "    #short_dist = pd.Series( np.where(total_minute < 360, 1, 0) )\n",
        "    #long_dist = pd.Series( np.where(total_minute < 360, 0, 1) )\n",
        "    #return (pd.concat([total_minute, short_dist, long_dist], axis = 1))\n",
        "    total_minute = pd.DataFrame(to_bin.fit_transform(pd.DataFrame(total_minute)))\n",
        "    return(total_minute)\n",
        "\n",
        "# Can we use subclass?\n",
        "class part_of_day(TransformerMixin):\n",
        "  def fit(self, X, y = None):\n",
        "    return self\n",
        "  \n",
        "  def transform(self, X):\n",
        "    col = pd.Series(X) \n",
        "    aseries = col.replace(\":\\d\\d.*\", \"\", regex = True).astype('int32')\n",
        "    conditions = [\n",
        "      (aseries > 6) & (aseries <= 13),\n",
        "      (aseries > 13) & (aseries <= 18),\n",
        "      (aseries > 18) & (aseries <= 21),\n",
        "      (aseries > 21) | (aseries <= 6)\n",
        "    ]\n",
        "\n",
        "    choices = ['morning', 'afternoon', 'eve', 'night']\n",
        "  \n",
        "    return np.select(conditions, choices, default='night')\n",
        "  \n",
        "\n",
        "class convert_stops(TransformerMixin):\n",
        "  def fit(self, X, y = None):\n",
        "    return self\n",
        "  \n",
        "  def transform(self, X):\n",
        "    col = pd.Series(X) \n",
        "    #aseries = \n",
        "    conditions = [\n",
        "      (col == \"non-stop\"),\n",
        "      (col == \"1 stop\"),\n",
        "      (col == \"2 stops\"),\n",
        "      (col == \"3 stops\"),\n",
        "      (col == \"4 stops\")\n",
        "    ]\n",
        "\n",
        "    choices = [0, 1, 2, 3, 4]\n",
        "  \n",
        "    return np.select(conditions, choices, default='0')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JNG0h6cwPJ_f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# As Route and Additional_Info are not defined they are dropped. \n",
        "# Write a default function for imputation\n",
        "\n",
        "mapper = DataFrameMapper([\n",
        "    ( 'Airline', encoder ),\n",
        "    ( 'Week', encoder ),\n",
        "    ( 'Month', encoder ),\n",
        "    ( 'Source', encoder ),\n",
        "    #( 'Destination', encoder ),\n",
        "    ( 'Dep_Time', [part_of_day(), encoder] ),\n",
        "    ( 'Arrival_Time', [part_of_day(), encoder] ),\n",
        "    ( 'Duration', to_min() ),\n",
        "    ( 'Total_Stops', [CategoricalImputer(strategy = \"most_frequent\"), convert_stops()] ),\n",
        "    ( 'class', encoder),\n",
        "    ( 'meal', encoder),\n",
        "    ( 'landingWeek', encoder),\n",
        "    ( 'checkin', encoder) # As these columns are binary, encoder does not apply on them.\n",
        "    #( 'Price', FunctionTransformer(np.log) ),\n",
        "], df_out = True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_mSZYOzW6Nc_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = train_data.drop(\"Price\", axis = 1)\n",
        "y = np.log(train_data['Price']).astype(float)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, stratify = X['Airline']) #Stratify\n",
        "\n",
        "#X_test, X_ftest, y_test, y_ftest = train_test_split(X_test, y_test, test_size = 0.10, stratify = X_test['Airline'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MTyX863SN9e9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# #Prepare pipeline and fit there.\n",
        "X_train = mapper.fit_transform(X_train).astype(float)#.drop(['Airline_Multiple carriers Premium economy'], axis = 1)\n",
        "X_test = mapper.fit_transform(X_test).astype(float)#.drop(['Airline_Multiple carriers Premium economy'], axis = 1)\n",
        "\n",
        "#Can we drop 'Airline_Multiple carriers Premium economy' in onehotencoder and use stacking?\n",
        "#X_ftest = mapper.fit_transform(X_ftest).astype(float)#.drop(['Airline_Multiple carriers Premium economy'], axis = 1)\n",
        "sub = mapper.fit_transform(sub_data).astype(float)#.drop(['Airline_Multiple carriers Premium economy'], axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0c_bxDnCBOmO",
        "colab_type": "code",
        "outputId": "28778f44-9002-4e8f-aace-f191837c2dc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "X_train.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Airline_Air Asia', 'Airline_Air India', 'Airline_GoAir',\n",
              "       'Airline_IndiGo', 'Airline_Jet Airways', 'Airline_Jet Airways Business',\n",
              "       'Airline_Multiple carriers',\n",
              "       'Airline_Multiple carriers Premium economy', 'Airline_SpiceJet',\n",
              "       'Airline_Vistara', 'Week_Friday', 'Week_Monday', 'Week_Saturday',\n",
              "       'Week_Sunday', 'Week_Thursday', 'Week_Tuesday', 'Week_Wednesday',\n",
              "       'Month_3', 'Month_4', 'Month_5', 'Month_6', 'Source_BangloreDelhi',\n",
              "       'Source_ChennaiKolkata', 'Source_DelhiCochin', 'Source_KolkataBanglore',\n",
              "       'Source_MumbaiHyderabad', 'Dep_Time_afternoon', 'Dep_Time_eve',\n",
              "       'Dep_Time_morning', 'Dep_Time_night', 'Arrival_Time_afternoon',\n",
              "       'Arrival_Time_eve', 'Arrival_Time_morning', 'Arrival_Time_night',\n",
              "       'Duration_0', 'Duration_1', 'Duration_2', 'Total_Stops', 'class',\n",
              "       'meal', 'landingWeek_Friday', 'landingWeek_Monday',\n",
              "       'landingWeek_Saturday', 'landingWeek_Sunday', 'landingWeek_Thursday',\n",
              "       'landingWeek_Tuesday', 'landingWeek_Wednesday', 'checkin'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "sRAp5gUC7DRp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Boosting\n",
        "\n",
        "Boosting in following format  \n",
        "Model based on default values  \n",
        "Model result on 5 parts of train data, using cv  \n",
        "RMSE on test data\n",
        "\n",
        "Hyperparameter tuning with GridSearch cv  \n",
        "grid result on 5 parts of train data  \n",
        "RMSE of test data using grid  \n",
        "\n",
        "Define boosting function"
      ]
    },
    {
      "metadata": {
        "id": "MFguRo-i9ET2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### XGBoost"
      ]
    },
    {
      "metadata": {
        "id": "M3rxeko19KgT",
        "colab_type": "code",
        "outputId": "302afe1b-09ba-4036-e642-6587a267eda1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "base_model = xgb.XGBRegressor(learning_rate=0.2, gamma= 0.01, max_depth = 7)\n",
        "base_model.fit(X_train, y_train)\n",
        "print( np.sqrt( -cross_val_score(base_model, X_train, y_train, cv = 5, scoring = \"neg_mean_squared_error\") ) )\n",
        "np.sqrt(mean_squared_error(np.exp(y_test), np.exp(base_model.predict(X_test))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.178591   0.17616793 0.17390439 0.17912586 0.18019413]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1791.5764380778703"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "K5FRYcsB1BFR",
        "colab_type": "code",
        "outputId": "dd918502-3fac-447e-8a2c-b417d153701d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "cell_type": "code",
      "source": [
        "xgb_engine = xgb.XGBRegressor() #n_estimator not used\n",
        "xgb_params = {'max_depth' : np.arange(1, 10, 3), 'gamma' : [0.01, 1], 'learning_rate' : [0.1, 0.2, 0.3]}\n",
        "\n",
        "xgb_grid = GridSearchCV(xgb_engine, xgb_params, cv = 5, n_jobs = -1, verbose = 1)\n",
        "xgb_grid.fit(X_train, y_train)\n",
        "\n",
        "print( np.sqrt( -cross_val_score(xgb_grid.best_estimator_, X_train, y_train, cv = 5, scoring = \"neg_mean_squared_error\") ) )\n",
        "print( np.sqrt( mean_squared_error(np.exp(y_test), np.exp(xgb_grid.predict(X_test))) ) )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   37.0s\n",
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  1.2min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0.178591   0.17616793 0.17390439 0.17912586 0.18019413]\n",
            "1791.5764380778703\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZyHP-Qz4795h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### GBM"
      ]
    },
    {
      "metadata": {
        "id": "M8antVp679gr",
        "colab_type": "code",
        "outputId": "f0c2cc8c-4358-444c-d618-8d7eb250007c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "gbm_model = GradientBoostingRegressor(learning_rate = 0.05, max_depth = 7, n_estimators = 300)\n",
        "gbm_model.fit(X_train, y_train)\n",
        "print( np.sqrt( -cross_val_score(gbm_model, X_train, y_train, cv = 5, scoring = \"neg_mean_squared_error\") ) )\n",
        "np.sqrt(mean_squared_error(np.exp(y_test), np.exp(gbm_model.predict(X_test))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.17969775 0.17595766 0.17173887 0.18166729 0.17842296]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1807.067138106383"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "ko_Rxz5eobCK",
        "colab_type": "code",
        "outputId": "afae338e-b5f7-448d-c7ec-2d2a995aeca1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "cell_type": "code",
      "source": [
        "gbm_engine = GradientBoostingRegressor()\n",
        "gbm_params = {'max_depth' : [7], 'learning_rate' : [0.05], 'n_estimators' : [300]}\n",
        "\n",
        "gbm_grid = GridSearchCV(gbm_engine, gbm_params, cv = 5, n_jobs = -1, verbose = 1)\n",
        "gbm_grid.fit(X_train, y_train)\n",
        "print( np.sqrt( -cross_val_score(gbm_grid.best_estimator_, X_train, y_train, cv = 5, scoring = \"neg_mean_squared_error\") ) )\n",
        "print( np.sqrt( mean_squared_error(np.exp(y_test), np.exp(gbm_grid.predict(X_test))) ) )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   42.0s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0.17870984 0.17615369 0.17154961 0.18142573 0.17863615]\n",
            "1816.3764133003674\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LapmourD6tbr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Light GBM"
      ]
    },
    {
      "metadata": {
        "id": "wvH_0Fo-7f20",
        "colab_type": "code",
        "outputId": "b269b4c4-e4ec-44b4-dd6f-dcfdcba7884e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "# https://lightgbm.readthedocs.io/en/latest/Python-API.html#scikit-learn-api\n",
        "# Use gridsearchcv\n",
        "\n",
        "import lightgbm as lgb\n",
        "lgbm_model = lgb.LGBMRegressor(learning_rate = 0.3, n_estimators = 300, max_depth = 6, min_child_samples  = 17)\n",
        "lgbm_model.fit(X_train.astype(float), y_train.astype(float))\n",
        "\n",
        "print( np.sqrt( -cross_val_score(lgbm_model, X_train.astype(float), y_train, cv = 5, scoring = \"neg_mean_squared_error\") ) )\n",
        "np.sqrt(mean_squared_error(np.exp(y_test), np.exp(lgbm_model.predict(X_test))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.18349371 0.18203957 0.17739656 0.18536029 0.18237333]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2032.2712991110502"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "jGSVUpmNrV5-",
        "colab_type": "code",
        "outputId": "c46d383c-cf91-4da7-ce2d-dc77d1690b46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "lgbm_engine = lgb.LGBMRegressor()\n",
        "lgbm_params = {'max_depth' : [6], 'learning_rate' : [ 0.3], 'n_estimators': [300], 'reg_alpha' : [0],  'min_child_samples' : [17]}\n",
        "\n",
        "lgbm_grid = GridSearchCV(lgbm_engine, lgbm_params, cv = 5, n_jobs = -1, verbose = 0)\n",
        "lgbm_grid.fit(X_train, y_train)\n",
        "print( np.sqrt( -cross_val_score(lgbm_grid.best_estimator_, X_train, y_train, cv = 5, scoring = \"neg_mean_squared_error\") ) )\n",
        "print( np.sqrt( mean_squared_error(np.exp(y_test), np.exp(lgbm_grid.predict(X_test))) ) )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.18349371 0.18203957 0.17739656 0.18536029 0.18237333]\n",
            "2032.2712991110502\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zdd-589LIJqA",
        "colab_type": "code",
        "outputId": "5a2fea8b-56ca-4c61-ec14-d24a98fbd5b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "for a, b, c in zip( lgbm_grid.cv_results_['params'], lgbm_grid.cv_results_['mean_test_score'], lgbm_grid.cv_results_['mean_train_score'] ):\n",
        "  print(a, b, c)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'learning_rate': 0.3, 'max_depth': 6, 'min_child_samples': 17, 'n_estimators': 300, 'reg_alpha': 0} 0.8734111632010509 0.9294670517830271\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
            "  warnings.warn(*warn_args, **warn_kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "uMaSD2jP7u57",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### AdaBoost"
      ]
    },
    {
      "metadata": {
        "id": "m2b2jXl87uVk",
        "colab_type": "code",
        "outputId": "1f7d6f2c-502e-4696-f29e-701982e90922",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "\n",
        "adb_model = AdaBoostRegressor(n_estimators = 300, learning_rate = 0.2)\n",
        "adb_model.fit(X_train, y_train)\n",
        "\n",
        "print( np.sqrt( -cross_val_score(adb_model, X_train, y_train, cv = 5, scoring = \"neg_mean_squared_error\") ) )\n",
        "np.sqrt(mean_squared_error(np.exp(y_test), np.exp(adb_model.predict(X_test))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.29303053 0.29382685 0.28953325 0.29818444 0.30160162]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3073.3280972438133"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "1Sbcs9ZKr9VW",
        "colab_type": "code",
        "outputId": "03831719-d635-411d-ffec-c4912d39d1db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "cell_type": "code",
      "source": [
        "adb_engine = AdaBoostRegressor()\n",
        "adb_params = {'n_estimators' : np.arange(50, 500, 50), 'learning_rate' : [0.1, 0.2, 0.3]}\n",
        "\n",
        "adb_grid = GridSearchCV(adb_engine, adb_params, cv = 5, n_jobs = -1, verbose = 1)\n",
        "adb_grid.fit(X_train, y_train)\n",
        "print( np.sqrt( -cross_val_score(adb_grid.best_estimator_, X_train, y_train, cv = 5, scoring = \"neg_mean_squared_error\") ) )\n",
        "print( np.sqrt( mean_squared_error(np.exp(y_test), np.exp(adb_grid.predict(X_test))) ) )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   59.3s\n",
            "[Parallel(n_jobs=-1)]: Done 135 out of 135 | elapsed:  2.0min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0.28912188 0.28287447 0.28223887 0.30034243 0.2959948 ]\n",
            "2957.2918846920384\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-M7GoWdd7IRC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Bagging"
      ]
    },
    {
      "metadata": {
        "id": "H2BuCDsyDcxR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ]
    },
    {
      "metadata": {
        "id": "tnDqu1NVDgBR",
        "colab_type": "code",
        "outputId": "4d41b22f-fb10-4013-8ac6-6a95c2df03c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "ranger_model = RandomForestRegressor(n_estimators = 100, oob_score = True)\n",
        "ranger_model.fit(X_train, y_train)\n",
        "print( np.sqrt( -cross_val_score(ranger_model, X_train, y_train, cv = 5, scoring = \"neg_mean_squared_error\") ) )\n",
        "np.sqrt(mean_squared_error(np.exp(y_test), np.exp(ranger_model.predict(X_test))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.18422773 0.18397932 0.18712185 0.19166247 0.18764033]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1889.2635548759438"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "9RuZfP47orYM",
        "colab_type": "code",
        "outputId": "9fe1e32a-56c0-4ae8-bdf2-6f95d9f5737c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "cell_type": "code",
      "source": [
        "ranger_engine = RandomForestRegressor()\n",
        "ranger_params = {'n_estimators' : np.arange(50, 500, 50)}\n",
        "\n",
        "ranger_grid = GridSearchCV(ranger_engine, ranger_params, cv = 5, n_jobs = -1, verbose = 1)\n",
        "ranger_grid.fit(X_train, y_train)\n",
        "print( np.sqrt( -cross_val_score(ranger_grid.best_estimator_, X_train, y_train, cv = 5, scoring = \"neg_mean_squared_error\") ) )\n",
        "print( np.sqrt( mean_squared_error(np.exp(y_test), np.exp(ranger_grid.predict(X_test))) ) )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  3.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0.18443997 0.18406537 0.18541716 0.19004336 0.18702247]\n",
            "1876.679538470102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Yu9osje-6XNd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Ensemble"
      ]
    },
    {
      "metadata": {
        "id": "UouYWt7h7YHo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Average ensemble"
      ]
    },
    {
      "metadata": {
        "id": "iUwVrYPgo4Gb",
        "colab_type": "code",
        "outputId": "738d4f5b-549b-4e28-dbcd-1a3a255fb4ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "cell_type": "code",
      "source": [
        "# Adaboost overfitting\n",
        "outcome = pd.DataFrame( {'-actual' : np.exp(y_test) , \n",
        "               'a-xgb' :np.exp(xgb_grid.predict(X_test)),\n",
        "               'b-gbm' : np.exp(gbm_grid.predict(X_test)),\n",
        "               'c-lgbm' : np.exp(lgbm_grid.predict(X_test))\n",
        "                        } )\n",
        "# 'd-ranger' : np.exp(ranger_grid.predict(X_test)) \n",
        "outcome['avg'] = outcome.mean(axis = 1)\n",
        "outcome.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>-actual</th>\n",
              "      <th>a-xgb</th>\n",
              "      <th>b-gbm</th>\n",
              "      <th>c-lgbm</th>\n",
              "      <th>avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2137.000000</td>\n",
              "      <td>2137.000000</td>\n",
              "      <td>2137.000000</td>\n",
              "      <td>2137.000000</td>\n",
              "      <td>2137.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>8950.171736</td>\n",
              "      <td>8949.885742</td>\n",
              "      <td>8942.968913</td>\n",
              "      <td>8916.697769</td>\n",
              "      <td>8939.933435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>4520.024280</td>\n",
              "      <td>4251.795898</td>\n",
              "      <td>4250.441276</td>\n",
              "      <td>4039.134974</td>\n",
              "      <td>4169.225012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1759.000000</td>\n",
              "      <td>1924.979736</td>\n",
              "      <td>1928.384833</td>\n",
              "      <td>1890.183717</td>\n",
              "      <td>1933.932452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>5135.000000</td>\n",
              "      <td>5482.491211</td>\n",
              "      <td>5419.284677</td>\n",
              "      <td>5396.261804</td>\n",
              "      <td>5429.892900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>8073.000000</td>\n",
              "      <td>8821.814453</td>\n",
              "      <td>8773.178055</td>\n",
              "      <td>8691.787748</td>\n",
              "      <td>8775.474397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>12373.000000</td>\n",
              "      <td>11545.903320</td>\n",
              "      <td>11507.910968</td>\n",
              "      <td>11524.779215</td>\n",
              "      <td>11692.389376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>57209.000000</td>\n",
              "      <td>61692.621094</td>\n",
              "      <td>62134.821177</td>\n",
              "      <td>31113.811850</td>\n",
              "      <td>51067.084038</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            -actual         a-xgb         b-gbm        c-lgbm           avg\n",
              "count   2137.000000   2137.000000   2137.000000   2137.000000   2137.000000\n",
              "mean    8950.171736   8949.885742   8942.968913   8916.697769   8939.933435\n",
              "std     4520.024280   4251.795898   4250.441276   4039.134974   4169.225012\n",
              "min     1759.000000   1924.979736   1928.384833   1890.183717   1933.932452\n",
              "25%     5135.000000   5482.491211   5419.284677   5396.261804   5429.892900\n",
              "50%     8073.000000   8821.814453   8773.178055   8691.787748   8775.474397\n",
              "75%    12373.000000  11545.903320  11507.910968  11524.779215  11692.389376\n",
              "max    57209.000000  61692.621094  62134.821177  31113.811850  51067.084038"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "F7yvuBgChlsn",
        "colab_type": "code",
        "outputId": "c378aa3b-2105-423f-a0d0-c67863ea7a9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# ens_predict = pd.DataFrame( { 'axgbpre' :np.exp(base_model.predict(X_test)) ,\n",
        "#                'brfpre' : np.exp(ranger.predict(X_test)) } ).mean(axis = 1)\n",
        "\n",
        "ens_predict = outcome['avg']\n",
        "\n",
        "np.sqrt( mean_squared_error(np.exp(y_test), ens_predict) )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1349.110237805378"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "isZUgSsMPM-l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Submit file"
      ]
    },
    {
      "metadata": {
        "id": "9VFsq7JyNVmG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#%%script false\n",
        "\n",
        "soutcome = pd.DataFrame({'a-xgb' :np.exp(xgb_grid.predict(sub)),\n",
        "               'b-gbm' : np.exp(gbm_grid.predict(sub)),\n",
        "               'c-lgbm' : np.exp(lgbm_grid.predict(sub.astype(float))) } )\n",
        "\n",
        "soutcome['avg'] = soutcome.mean(axis = 1)\n",
        "\n",
        "pd.DataFrame({ \"Price\" : soutcome['avg'] }, index = None).to_csv(\"FlightPriceEn.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "scJq7Gv5X1dC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Stacking\n",
        "\n",
        "A pipeline needed"
      ]
    },
    {
      "metadata": {
        "id": "BhvK3BQwX5Ba",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%script false\n",
        "\n",
        "X_stack = pd.DataFrame( {'axgbpre' :base_model.predict(X_test) ,\n",
        "                         'gbm' : gbm.predict(X_test),\n",
        "                         'lgbm' : lgbm.predict(X_test),\n",
        "                          'adb' : adb.predict(X_test)})\n",
        "\n",
        "y_stack = y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PQ3k-jmFZHuF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%script false\n",
        "\n",
        "stack_model = xgb.XGBRegressor(learning_rate=0.05, n_estimators = 1000) #learning_rate=0.2, gamma= 0.01, max_depth = 7\n",
        "#stack_model.fit(X_stack, y_stack)\n",
        "params = {\"max_depth\" : [2, 5, 7]}\n",
        "ensemble_grid = GridSearchCV(stack_model, params, cv = 5)\n",
        "ensemble_grid.fit(X_stack, y_stack)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MPN7YtACUoHc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%script false\n",
        "\n",
        "ensemble_grid.best_estimator_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yUCqKL-6S5Ty",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%script false\n",
        "\n",
        "np.sqrt( -cross_val_score(ensemble_grid, X_stack, y_stack, cv = 5, scoring = \"neg_mean_squared_error\") )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r4nkx43oW9Pc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%script false\n",
        "\n",
        "#column Airline_Jet Airways Business, Airline_Multiple carriers Premium economy are not available in ftest\n",
        "X_stack = pd.DataFrame( {'axgbpre' :base_model.predict(X_ftest) ,\n",
        "                         'gbm' : gbm.predict(X_ftest),\n",
        "                         'lgbm' : lgbm.predict(X_ftest),\n",
        "                          'adb' : adb.predict(X_ftest)})\n",
        "\n",
        "y_stack = y_ftest\n",
        "np.sqrt( mean_squared_error(np.exp(y_ftest), np.exp(ensemble_grid.predict(X_stack))) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JWpSkl7zav8M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## KNN"
      ]
    },
    {
      "metadata": {
        "id": "JQJMhHHlazXc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6mjCnD3Z7PrS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Playground models"
      ]
    },
    {
      "metadata": {
        "id": "Nmf8OqYUpwMD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Support Vector Regression - not amazing\n",
        "Apply appropriate transformation"
      ]
    },
    {
      "metadata": {
        "id": "DQJ8BkCzpvd6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%script false\n",
        "\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.preprocessing import StandardScaler, normalize\n",
        "\n",
        "#scaler = StandardScaler()\n",
        "#svr_model = SVR(gamma = 'scale')\n",
        "\n",
        "svmpipe = Pipeline([ ( \"std\", StandardScaler() ), ( \"svm\", SVR(gamma = 'scale', kernel = 'rbf', C = 1.5, epsilon = 0.1, max_iter=-1) ) ])\n",
        "svmpipe.fit(X_train.astype(float), y_train.astype(float))\n",
        "\n",
        "np.sqrt( -cross_val_score(svmpipe, X_train.astype(float), y_train.astype(float), cv = 5, scoring = \"neg_mean_squared_error\") )\n",
        "np.sqrt( mean_squared_error(np.exp(y_test), np.exp(svmpipe.predict(X_test.astype(float)))) )\n",
        "pd.DataFrame( {'act' : np.exp(y_test) , 'axgbpre' :np.exp(svmpipe.predict(X_test.astype(float)))  } ).describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QU7-V0NvLIc_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Ridge - not a good result"
      ]
    },
    {
      "metadata": {
        "id": "XXuVEdweLH0w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%script false\n",
        "\n",
        "from sklearn.linear_model import RidgeCV\n",
        "\n",
        "ridge_model = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1], cv = 5).fit(X_train.astype(float), y_train.astype(float))\n",
        "np.sqrt( -cross_val_score(ridge_model, X_train.astype(float), y_train.astype(float), cv = 5, scoring = \"neg_mean_squared_error\") )\n",
        "np.sqrt(mean_squared_error(npa.exp(y_test.astype(float)), np.exp(ridge_model.predict(X_test.astype(float)))))\n",
        "\n",
        "pd.DataFrame( {'act' : np.exp(y_test) , \n",
        "               'axgbpre' :np.exp(base_model.predict(X_test)) ,\n",
        "               'brfpre' : np.exp(ranger.predict(X_test)),\n",
        "               'cridge' : np.exp(ridge_model.predict(X_test.astype(float))) } ).describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2lBcWgj8n_wU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### LASSO - Not a good result"
      ]
    },
    {
      "metadata": {
        "id": "5MvP-kBUn_Jv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%script false \n",
        "\n",
        "from sklearn.linear_model import LassoCV\n",
        "\n",
        "lasso_model = LassoCV(alphas=[1e-3, 1e-2, 1e-1, 1], cv = 5).fit(X_train.astype(float), y_train.astype(float))\n",
        "np.sqrt( -cross_val_score(lasso_model, X_train.astype(float), y_train.astype(float), cv = 5, scoring = \"neg_mean_squared_error\") )\n",
        "np.sqrt(mean_squared_error(np.exp(y_test.astype(float)), np.exp(lasso_model.predict(X_test.astype(float)))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B_oq1ftJL4zX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Neural Network - worst"
      ]
    },
    {
      "metadata": {
        "id": "MB9pCcl_L4OP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%script false\n",
        "\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "def baseline_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(100, input_dim=12, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dense(50, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dense(1, kernel_initializer='normal'))\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "    return model\n",
        "  \n",
        "#model.fit(X_train, y_train)\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasRegressor(build_fn=baseline_model, epochs=5, verbose = 0, validation_split = 0.20)))\n",
        "pipeline = Pipeline(estimators)\n",
        "#estimator = KerasRegressor(build_fn=baseline_model, epochs=10, batch_size=5, verbose=0)\n",
        "# np.sqrt( -cross_val_score(pipeline, X_train.astype(float), y_train.astype(float), cv = 5, scoring = \"neg_mean_squared_error\") )"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}