{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stacked",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "sRAp5gUC7DRp",
        "MFguRo-i9ET2",
        "ZyHP-Qz4795h",
        "LapmourD6tbr",
        "uMaSD2jP7u57",
        "-M7GoWdd7IRC",
        "H2BuCDsyDcxR",
        "scJq7Gv5X1dC",
        "6mjCnD3Z7PrS",
        "Nmf8OqYUpwMD",
        "QU7-V0NvLIc_",
        "2lBcWgj8n_wU",
        "B_oq1ftJL4zX"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "jbPbxS7j7ldq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Import"
      ]
    },
    {
      "metadata": {
        "id": "vU0OsVfsNXot",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!pip install sklearn_pandas"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DiPgWfb0198k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def temp_to_min(X):\n",
        "    hour, minute = pd.Series(X).str.split(\" \", 1).str\n",
        "    hour = pd.Series(hour).str.replace(\"h\", \" \")\n",
        "    hour = hour.astype('int64')\n",
        "    minute = pd.Series(minute).str.replace(\"m\", \" \")\n",
        "    minute = minute.fillna(0)\n",
        "    minute = minute.astype('int64')\n",
        "    total_minute = pd.to_timedelta( (hour * 60) + minute, unit = \"m\" )\n",
        "    return(total_minute)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PaFnbqn3672t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Load modules"
      ]
    },
    {
      "metadata": {
        "id": "GI053nEcEEFn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn_pandas import DataFrameMapper, FunctionTransformer, CategoricalImputer\n",
        "from sklearn.preprocessing import LabelEncoder, LabelBinarizer, KBinsDiscretizer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.base import TransformerMixin\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bylysnf0ERxD",
        "colab_type": "code",
        "outputId": "863f2279-dd5d-4da8-a937-6d4a9bf0e222",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pIgI_vC6wsPf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Data Cleaning"
      ]
    },
    {
      "metadata": {
        "id": "P-EU7e1WEdB7",
        "colab_type": "code",
        "outputId": "4e090893-7cde-4708-f8b3-2100bdb2a9cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv(\"drive/My Drive/PyColab Work/FlightPricePredict/train.csv\")\n",
        "sub_data = pd.read_csv(\"drive/My Drive/PyColab Work/FlightPricePredict/test.csv\")\n",
        "#train_data.drop(index = 6474, inplace = True, axis = 0) # 5m flight time #change to 24hr 5m\n",
        "train_data.iloc[6474, 7] = \"24h 5m\"\n",
        "sub_data.iloc[2660, 7] = \"24h 5m\"\n",
        "\n",
        "train_data.iloc[1478, 0] = \"Jet Airways Business\"\n",
        "train_data.iloc[2618, 0] = \"Jet Airways Business\"\n",
        "train_data.iloc[5439, 0] = \"Jet Airways Business\"\n",
        "\n",
        "train_data.drop(index = 2924, inplace = True, axis = 0)\n",
        "#train_data.drop(index = 5136, inplace = True, axis = 0)\n",
        "#train_data.drop(index = 2618, inplace = True, axis = 0)\n",
        "#train_data.drop(index = 5439, inplace = True, axis = 0)\n",
        "\n",
        "\n",
        "# Date need to be looked at # Move this\n",
        "train_data[\"Week\"] = pd.to_datetime(train_data[\"Date_of_Journey\"], dayfirst = True).dt.weekday_name\n",
        "train_data[\"Month\"] = pd.to_datetime(train_data[\"Date_of_Journey\"], dayfirst = True).dt.month\n",
        "train_data[\"Airline\"] = train_data.Airline.replace(\"Trujet\", \"SpiceJet\")\n",
        "train_data[\"class\"] = np.where(train_data['Airline']=='Jet Airways Business', 'High', 'Low')\n",
        "train_data[\"meal\"] = np.where(train_data['Additional_Info']=='In-flight meal not included', 'High', 'Low')\n",
        "train_data[\"checkin\"] = np.where(train_data['Additional_Info']=='No check-in baggage included', 'High', 'Low')\n",
        "train_data[\"Destination\"] = np.where(train_data[\"Destination\"] == \"New Delhi\", \"Delhi\", train_data[\"Destination\"])\n",
        "train_data[\"Airline\"] = np.where(train_data[\"Airline\"] == \"Vistara Premium economy\", \"Multiple carriers\", train_data[\"Airline\"])\n",
        "train_data[\"Airline\"] = np.where(train_data[\"Airline\"] == \"Multiple carriers Premium economy\", \"Multiple carriers\", train_data[\"Airline\"])\n",
        "#train_data[\"S1\"], train_data[\"S2\"], train_data['S3'], train_data[\"S4\"], train_data['S5'], train_data[\"S6\"] = train_data.Route.str.replace(\"?\", \"-\").str.split(\" - \").str\n",
        "#train_data.fillna(\"NA\", axis = 1, inplace = True)\n",
        "train_data['landing'] = pd.to_datetime(train_data['Date_of_Journey'] + '-' + train_data['Dep_Time'], dayfirst = True) + temp_to_min(train_data[\"Duration\"])\n",
        "train_data[\"landingWeek\"] = pd.to_datetime(train_data[\"landing\"]).dt.weekday_name\n",
        "train_data[\"Source\"] = train_data[\"Source\"] + train_data[\"Destination\"]\n",
        "\n",
        "  \n",
        "train_data['landing'] = pd.to_datetime(train_data['Date_of_Journey'] + '-' + train_data['Dep_Time']) + temp_to_min(train_data[\"Duration\"])\n",
        "train_data[\"landingWeek\"] = pd.to_datetime(train_data[\"landing\"]).dt.weekday_name\n",
        "train_data.drop(['Route', 'Destination'], axis = 1).head()\n",
        "\n",
        "#Seperate y here itself"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Airline</th>\n",
              "      <th>Date_of_Journey</th>\n",
              "      <th>Source</th>\n",
              "      <th>Destination</th>\n",
              "      <th>Dep_Time</th>\n",
              "      <th>Arrival_Time</th>\n",
              "      <th>Duration</th>\n",
              "      <th>Total_Stops</th>\n",
              "      <th>Additional_Info</th>\n",
              "      <th>Price</th>\n",
              "      <th>Week</th>\n",
              "      <th>Month</th>\n",
              "      <th>class</th>\n",
              "      <th>meal</th>\n",
              "      <th>checkin</th>\n",
              "      <th>landing</th>\n",
              "      <th>landingWeek</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>IndiGo</td>\n",
              "      <td>24/03/2019</td>\n",
              "      <td>BangloreDelhi</td>\n",
              "      <td>Delhi</td>\n",
              "      <td>22:20</td>\n",
              "      <td>01:10 22 Mar</td>\n",
              "      <td>2h 50m</td>\n",
              "      <td>non-stop</td>\n",
              "      <td>No info</td>\n",
              "      <td>3897</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>3</td>\n",
              "      <td>Low</td>\n",
              "      <td>Low</td>\n",
              "      <td>Low</td>\n",
              "      <td>2019-03-25 01:10:00</td>\n",
              "      <td>Monday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Air India</td>\n",
              "      <td>1/05/2019</td>\n",
              "      <td>KolkataBanglore</td>\n",
              "      <td>Banglore</td>\n",
              "      <td>05:50</td>\n",
              "      <td>13:15</td>\n",
              "      <td>7h 25m</td>\n",
              "      <td>2 stops</td>\n",
              "      <td>No info</td>\n",
              "      <td>7662</td>\n",
              "      <td>Wednesday</td>\n",
              "      <td>5</td>\n",
              "      <td>Low</td>\n",
              "      <td>Low</td>\n",
              "      <td>Low</td>\n",
              "      <td>2019-01-05 13:15:00</td>\n",
              "      <td>Saturday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Jet Airways</td>\n",
              "      <td>9/06/2019</td>\n",
              "      <td>DelhiCochin</td>\n",
              "      <td>Cochin</td>\n",
              "      <td>09:25</td>\n",
              "      <td>04:25 10 Jun</td>\n",
              "      <td>19h</td>\n",
              "      <td>2 stops</td>\n",
              "      <td>No info</td>\n",
              "      <td>13882</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>6</td>\n",
              "      <td>Low</td>\n",
              "      <td>Low</td>\n",
              "      <td>Low</td>\n",
              "      <td>2019-09-07 04:25:00</td>\n",
              "      <td>Saturday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>IndiGo</td>\n",
              "      <td>12/05/2019</td>\n",
              "      <td>KolkataBanglore</td>\n",
              "      <td>Banglore</td>\n",
              "      <td>18:05</td>\n",
              "      <td>23:30</td>\n",
              "      <td>5h 25m</td>\n",
              "      <td>1 stop</td>\n",
              "      <td>No info</td>\n",
              "      <td>6218</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>5</td>\n",
              "      <td>Low</td>\n",
              "      <td>Low</td>\n",
              "      <td>Low</td>\n",
              "      <td>2019-12-05 23:30:00</td>\n",
              "      <td>Thursday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>IndiGo</td>\n",
              "      <td>01/03/2019</td>\n",
              "      <td>BangloreDelhi</td>\n",
              "      <td>Delhi</td>\n",
              "      <td>16:50</td>\n",
              "      <td>21:35</td>\n",
              "      <td>4h 45m</td>\n",
              "      <td>1 stop</td>\n",
              "      <td>No info</td>\n",
              "      <td>13302</td>\n",
              "      <td>Friday</td>\n",
              "      <td>3</td>\n",
              "      <td>Low</td>\n",
              "      <td>Low</td>\n",
              "      <td>Low</td>\n",
              "      <td>2019-01-03 21:35:00</td>\n",
              "      <td>Thursday</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Airline Date_of_Journey           Source Destination Dep_Time  \\\n",
              "0       IndiGo      24/03/2019    BangloreDelhi       Delhi    22:20   \n",
              "1    Air India       1/05/2019  KolkataBanglore    Banglore    05:50   \n",
              "2  Jet Airways       9/06/2019      DelhiCochin      Cochin    09:25   \n",
              "3       IndiGo      12/05/2019  KolkataBanglore    Banglore    18:05   \n",
              "4       IndiGo      01/03/2019    BangloreDelhi       Delhi    16:50   \n",
              "\n",
              "   Arrival_Time Duration Total_Stops Additional_Info  Price       Week  Month  \\\n",
              "0  01:10 22 Mar   2h 50m    non-stop         No info   3897     Sunday      3   \n",
              "1         13:15   7h 25m     2 stops         No info   7662  Wednesday      5   \n",
              "2  04:25 10 Jun      19h     2 stops         No info  13882     Sunday      6   \n",
              "3         23:30   5h 25m      1 stop         No info   6218     Sunday      5   \n",
              "4         21:35   4h 45m      1 stop         No info  13302     Friday      3   \n",
              "\n",
              "  class meal checkin             landing landingWeek  \n",
              "0   Low  Low     Low 2019-03-25 01:10:00      Monday  \n",
              "1   Low  Low     Low 2019-01-05 13:15:00    Saturday  \n",
              "2   Low  Low     Low 2019-09-07 04:25:00    Saturday  \n",
              "3   Low  Low     Low 2019-12-05 23:30:00    Thursday  \n",
              "4   Low  Low     Low 2019-01-03 21:35:00    Thursday  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "2NmJ5-HD2U3F",
        "colab_type": "code",
        "outputId": "fc7bde71-fcb5-4403-e25a-5afeb44d1e73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "cell_type": "code",
      "source": [
        "train_data.Airline.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Jet Airways             3846\n",
              "IndiGo                  2053\n",
              "Air India               1752\n",
              "Multiple carriers       1212\n",
              "SpiceJet                 819\n",
              "Vistara                  479\n",
              "Air Asia                 319\n",
              "GoAir                    194\n",
              "Jet Airways Business       8\n",
              "Name: Airline, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "7bUx7Eslr9EM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%script false\n",
        "\n",
        "def flight_data_clean(df) :\n",
        "  df[\"Week\"] = pd.to_datetime(df[\"Date_of_Journey\"]).dt.weekday\n",
        "  df[\"Month\"] = pd.to_datetime(df[\"Date_of_Journey\"]).dt.month\n",
        "  df = df.drop(['Date_of_Journey','Route', 'Additional_Info'], axis = 1)\n",
        "  df = pd.get_dummies(df, columns=['Airline', 'Source', 'Destination', 'Total_Stops'])\n",
        "  return(df)\n",
        "\n",
        "flight_data_clean(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FRdcAH2oslGt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sub_data[\"Week\"] = pd.to_datetime(sub_data[\"Date_of_Journey\"], dayfirst = True).dt.weekday_name\n",
        "sub_data[\"Month\"] = pd.to_datetime(sub_data[\"Date_of_Journey\"], dayfirst = True).dt.month\n",
        "sub_data[\"class\"] = np.where(sub_data['Airline']=='Jet Airways Business', 'High', 'Low')\n",
        "sub_data[\"meal\"] = np.where(sub_data['Additional_Info']=='In-flight meal not included', 'High', 'Low')\n",
        "sub_data[\"checkin\"] = np.where(sub_data['Additional_Info']=='No check-in baggage included', 'High', 'Low')\n",
        "sub_data[\"Destination\"] = np.where(sub_data[\"Destination\"] == \"New Delhi\", \"Delhi\", sub_data[\"Destination\"])\n",
        "train_data[\"Airline\"] = np.where(train_data[\"Airline\"] == \"Vistara Premium economy\", \"Multiple carriers\", train_data[\"Airline\"])\n",
        "train_data[\"Airline\"] = np.where(train_data[\"Airline\"] == \"Multiple carriers Premium economy\", \"Multiple carriers\", train_data[\"Airline\"])\n",
        "sub_data['landing'] = pd.to_datetime(sub_data['Date_of_Journey'] + '-' + sub_data['Dep_Time']) + temp_to_min(sub_data[\"Duration\"])\n",
        "sub_data[\"landingWeek\"] = pd.to_datetime(sub_data[\"landing\"]).dt.weekday_name\n",
        "#sub_data[\"S1\"], sub_data[\"S2\"], sub_data['S3'], sub_data[\"S4\"], sub_data['S5'], sub_data[\"S6\"] = sub_data.Route.str.replace(\"?\", \"-\").str.split(\" - \").str\n",
        "#sub_data.fillna(\"NA\", axis = 1, inplace = True)\n",
        "train_data['landing'] = pd.to_datetime(train_data['Date_of_Journey'] + '-' + train_data['Dep_Time'], dayfirst = True) + temp_to_min(train_data[\"Duration\"])\n",
        "train_data[\"landingWeek\"] = pd.to_datetime(train_data[\"landing\"]).dt.weekday_name\n",
        "train_data[\"Source\"] = train_data[\"Source\"] + train_data[\"Destination\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2D1eR-kDNddZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoder = LabelBinarizer() # LabelBinarizer()  ~~#LabelEncoder()~~\n",
        "to_bin = KBinsDiscretizer(n_bins=3, encode = 'onehot-dense')\n",
        "\n",
        "\n",
        "class to_min(TransformerMixin):\n",
        "  \n",
        "  def fit(self, X, y=None):\n",
        "    return self\n",
        "  \n",
        "  def transform(self, X):\n",
        "    hour, minute = pd.Series(X).str.split(\" \", 1).str\n",
        "    hour = pd.Series(hour).str.replace(\"h\", \" \")\n",
        "    hour = hour.astype('int64')\n",
        "    minute = pd.Series(minute).str.replace(\"m\", \" \")\n",
        "    minute = minute.fillna(0)\n",
        "    minute = minute.astype('int64')\n",
        "    total_minute = pd.Series( (hour * 60) + minute )\n",
        "    #short_dist = pd.Series( np.where(total_minute < 360, 1, 0) )\n",
        "    #long_dist = pd.Series( np.where(total_minute < 360, 0, 1) )\n",
        "    #return (pd.concat([total_minute, short_dist, long_dist], axis = 1))\n",
        "    total_minute = pd.DataFrame(to_bin.fit_transform(pd.DataFrame(total_minute)))\n",
        "    return(total_minute)\n",
        "\n",
        "# Can we use subclass?\n",
        "class part_of_day(TransformerMixin):\n",
        "  def fit(self, X, y = None):\n",
        "    return self\n",
        "  \n",
        "  def transform(self, X):\n",
        "    col = pd.Series(X) \n",
        "    aseries = col.replace(\":\\d\\d.*\", \"\", regex = True).astype('int32')\n",
        "    conditions = [\n",
        "      (aseries > 6) & (aseries <= 13),\n",
        "      (aseries > 13) & (aseries <= 18),\n",
        "      (aseries > 18) & (aseries <= 21),\n",
        "      (aseries > 21) | (aseries <= 6)\n",
        "    ]\n",
        "\n",
        "    choices = ['morning', 'afternoon', 'eve', 'night']\n",
        "  \n",
        "    return np.select(conditions, choices, default='night')\n",
        "  \n",
        "\n",
        "class convert_stops(TransformerMixin):\n",
        "  def fit(self, X, y = None):\n",
        "    return self\n",
        "  \n",
        "  def transform(self, X):\n",
        "    col = pd.Series(X) \n",
        "    #aseries = \n",
        "    conditions = [\n",
        "      (col == \"non-stop\"),\n",
        "      (col == \"1 stop\"),\n",
        "      (col == \"2 stops\"),\n",
        "      (col == \"3 stops\"),\n",
        "      (col == \"4 stops\")\n",
        "    ]\n",
        "\n",
        "    choices = [0, 1, 2, 3, 4]\n",
        "  \n",
        "    return np.select(conditions, choices, default='0')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JNG0h6cwPJ_f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# As Route and Additional_Info are not defined they are dropped. \n",
        "# Write a default function for imputation\n",
        "\n",
        "mapper = DataFrameMapper([\n",
        "    ( 'Airline', encoder ),\n",
        "    ( 'Week', encoder ),\n",
        "    ( 'Month', encoder ),\n",
        "    ( 'Source', encoder ),\n",
        "    ( 'Destination', encoder ),\n",
        "    ( 'Dep_Time', [part_of_day(), encoder] ),\n",
        "    ( 'Arrival_Time', [part_of_day(), encoder] ),\n",
        "    #( 'Duration', to_min() ),\n",
        "    ( 'Total_Stops', [CategoricalImputer(strategy = \"most_frequent\"), convert_stops()] ),\n",
        "    ( 'class', encoder),\n",
        "    ( 'meal', encoder),\n",
        "    #( 'S1', encoder),\n",
        "    #( 'S2', encoder),\n",
        "    #( 'S3', encoder),\n",
        "    #( 'S4', encoder),\n",
        "    #( 'S5', encoder),\n",
        "    ( 'landingWeek', encoder),\n",
        "    ( 'checkin', encoder) # As these columns are binary, encoder does not apply on them.\n",
        "    #( 'Price', FunctionTransformer(np.log) ),\n",
        "], df_out = True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_mSZYOzW6Nc_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = train_data.drop(\"Price\", axis = 1)\n",
        "y = np.log(train_data['Price']).astype(float)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, stratify = X['Airline']) #Stratify\n",
        "\n",
        "X_test, X_ftest, y_test, y_ftest = train_test_split(X_test, y_test, test_size = 0.10, stratify = X_test['Airline'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MTyX863SN9e9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## IF ERROR THEN RUN PREVIOUS CELL.\n",
        "\n",
        "# #Prepare pipeline and fit there.\n",
        "X_train = mapper.fit_transform(X_train).astype(float).drop(['Airline_Jet Airways Business'], axis = 1)\n",
        "X_test = mapper.fit_transform(X_test).astype(float).drop(['Airline_Jet Airways Business'], axis = 1)\n",
        "\n",
        "#Can we drop 'Airline_Multiple carriers Premium economy' in onehotencoder and use stacking?\n",
        "X_ftest = mapper.fit_transform(X_ftest).astype(float)\n",
        "sub = mapper.fit_transform(sub_data).astype(float).drop(['Airline_Jet Airways Business'], axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0c_bxDnCBOmO",
        "colab_type": "code",
        "outputId": "6a1e0ce7-447d-4a91-cad9-87464671463f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "cell_type": "code",
      "source": [
        "X_train.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Airline_Air Asia', 'Airline_Air India', 'Airline_GoAir',\n",
              "       'Airline_IndiGo', 'Airline_Jet Airways', 'Airline_Multiple carriers',\n",
              "       'Airline_SpiceJet', 'Airline_Vistara', 'Week_Friday', 'Week_Monday',\n",
              "       'Week_Saturday', 'Week_Sunday', 'Week_Thursday', 'Week_Tuesday',\n",
              "       'Week_Wednesday', 'Month_3', 'Month_4', 'Month_5', 'Month_6',\n",
              "       'Source_BangloreDelhiDelhi', 'Source_ChennaiKolkataKolkata',\n",
              "       'Source_DelhiCochinCochin', 'Source_KolkataBangloreBanglore',\n",
              "       'Source_MumbaiHyderabadHyderabad', 'Destination_Banglore',\n",
              "       'Destination_Cochin', 'Destination_Delhi', 'Destination_Hyderabad',\n",
              "       'Destination_Kolkata', 'Dep_Time_afternoon', 'Dep_Time_eve',\n",
              "       'Dep_Time_morning', 'Dep_Time_night', 'Arrival_Time_afternoon',\n",
              "       'Arrival_Time_eve', 'Arrival_Time_morning', 'Arrival_Time_night',\n",
              "       'Total_Stops', 'class', 'meal', 'landingWeek_Friday',\n",
              "       'landingWeek_Monday', 'landingWeek_Saturday', 'landingWeek_Sunday',\n",
              "       'landingWeek_Thursday', 'landingWeek_Tuesday', 'landingWeek_Wednesday',\n",
              "       'checkin'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "sRAp5gUC7DRp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Boosting\n",
        "\n",
        "Boosting in following format  \n",
        "Model based on default values  \n",
        "Model result on 5 parts of train data, using cv  \n",
        "RMSE on test data\n",
        "\n",
        "Hyperparameter tuning with GridSearch cv  \n",
        "grid result on 5 parts of train data  \n",
        "RMSE of test data using grid  \n",
        "\n",
        "Define boosting function"
      ]
    },
    {
      "metadata": {
        "id": "MFguRo-i9ET2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### XGBoost"
      ]
    },
    {
      "metadata": {
        "id": "M3rxeko19KgT",
        "colab_type": "code",
        "outputId": "15275833-41ee-4df6-fa2e-a67539fc223f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "base_model = xgb.XGBRegressor(learning_rate=0.2, gamma= 0.01, max_depth = 7)\n",
        "base_model.fit(X_train, y_train)\n",
        "print( np.sqrt( -cross_val_score(base_model, X_train, y_train, cv = 5, scoring = \"neg_mean_squared_error\") ) )\n",
        "#np.sqrt(mean_squared_error(y_test, base_model.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.17301387 0.18327945 0.17090015 0.18431581 0.18509788]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K5FRYcsB1BFR",
        "colab_type": "code",
        "outputId": "5a4cc682-aa89-48b9-d7fb-afed77796a6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "cell_type": "code",
      "source": [
        "xgb_engine = xgb.XGBRegressor() #n_estimator not used\n",
        "xgb_params = {'max_depth' : np.arange(1, 10, 3), 'gamma' : [0.01, 1], 'learning_rate' : [0.1, 0.2, 0.3]}\n",
        "\n",
        "xgb_grid = GridSearchCV(xgb_engine, xgb_params, cv = 5, n_jobs = -1, verbose = 1)\n",
        "xgb_grid.fit(X_train, y_train)\n",
        "\n",
        "print( np.sqrt( -cross_val_score(xgb_grid.best_estimator_, X_train, y_train, cv = 5, scoring = \"neg_mean_squared_error\") ) )\n",
        "#print( np.sqrt( mean_squared_error(y_test, xgb_grid.predict(X_test)) ) )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   37.3s\n",
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  1.2min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0.16792932 0.18366188 0.17221405 0.18038188 0.18177267]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZyHP-Qz4795h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### GBM"
      ]
    },
    {
      "metadata": {
        "id": "M8antVp679gr",
        "colab_type": "code",
        "outputId": "b45381ff-8050-4506-f751-6bd1fb94d5b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "gbm_model = GradientBoostingRegressor(learning_rate = 0.05, max_depth = 7, n_estimators = 300)\n",
        "gbm_model.fit(X_train, y_train)\n",
        "print( np.sqrt( -cross_val_score(gbm_model, X_train, y_train, cv = 5, scoring = \"neg_mean_squared_error\") ) )\n",
        "#np.sqrt(mean_squared_error(y_test, gbm_model.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.17133946 0.18057683 0.17254508 0.18346578 0.18350606]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ko_Rxz5eobCK",
        "colab_type": "code",
        "outputId": "d3168e66-f8be-4f91-ae40-3790d2aaead5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "gbm_engine = GradientBoostingRegressor()\n",
        "gbm_params = {'max_depth' : [7], 'learning_rate' : [0.05], 'n_estimators' : [300]}\n",
        "\n",
        "gbm_grid = GridSearchCV(gbm_engine, gbm_params, cv = 5, n_jobs = -1, verbose = 1)\n",
        "gbm_grid.fit(X_train, y_train)\n",
        "print( np.sqrt( -cross_val_score(gbm_grid.best_estimator_, X_train, y_train, cv = 5, scoring = \"neg_mean_squared_error\") ) )\n",
        "#print( np.sqrt( mean_squared_error(y_test, gbm_grid.predict(X_test)) ) )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   44.8s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0.17139026 0.18038553 0.17257603 0.18338398 0.18363047]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LapmourD6tbr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Light GBM"
      ]
    },
    {
      "metadata": {
        "id": "wvH_0Fo-7f20",
        "colab_type": "code",
        "outputId": "50122ce0-3636-4049-f53c-d4645de98ec4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "# https://lightgbm.readthedocs.io/en/latest/Python-API.html#scikit-learn-api\n",
        "# Use gridsearchcv\n",
        "\n",
        "import lightgbm as lgb\n",
        "lgbm_model = lgb.LGBMRegressor(learning_rate = 0.3, n_estimators = 300, max_depth = 6, min_child_samples  = 17)\n",
        "lgbm_model.fit(X_train.astype(float), y_train.astype(float))\n",
        "\n",
        "print( np.sqrt( -cross_val_score(lgbm_model, X_train.astype(float), y_train, cv = 5, scoring = \"neg_mean_squared_error\") ) )\n",
        "np.sqrt(mean_squared_error(y_test, lgbm_model.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.17592686 0.1912921  0.17828105 0.18802441 0.18673964]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.18826264302088913"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "jGSVUpmNrV5-",
        "colab_type": "code",
        "outputId": "0e10c4d7-3d53-457b-c0d4-b26e8811d23c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "lgbm_engine = lgb.LGBMRegressor()\n",
        "lgbm_params = {'max_depth' : [6], 'learning_rate' : [ 0.3], 'n_estimators': [300], 'reg_alpha' : [0],  'min_child_samples' : [17]}\n",
        "\n",
        "lgbm_grid = GridSearchCV(lgbm_engine, lgbm_params, cv = 5, n_jobs = -1, verbose = 0)\n",
        "lgbm_grid.fit(X_train, y_train)\n",
        "print( np.sqrt( -cross_val_score(lgbm_grid.best_estimator_, X_train, y_train, cv = 5, scoring = \"neg_mean_squared_error\") ) )\n",
        "print( np.sqrt( mean_squared_error(y_test, lgbm_grid.predict(X_test)) ) )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.17592686 0.1912921  0.17828105 0.18802441 0.18673964]\n",
            "0.18826264302088913\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zdd-589LIJqA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for a, b, c in zip( lgbm_grid.cv_results_['params'], lgbm_grid.cv_results_['mean_test_score'], lgbm_grid.cv_results_['mean_train_score'] ):\n",
        "  print(a, b, c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uMaSD2jP7u57",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### AdaBoost"
      ]
    },
    {
      "metadata": {
        "id": "m2b2jXl87uVk",
        "colab_type": "code",
        "outputId": "e640600c-ac14-4266-812f-a6f68cf6eab9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "\n",
        "adb_model = AdaBoostRegressor(n_estimators = 300, learning_rate = 0.2)\n",
        "adb_model.fit(X_train, y_train)\n",
        "\n",
        "print( np.sqrt( -cross_val_score(adb_model, X_train, y_train, cv = 5, scoring = \"neg_mean_squared_error\") ) )\n",
        "np.sqrt(mean_squared_error(y_test, adb_model.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.28595187 0.29305241 0.29082044 0.29939831 0.29153977]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.29668692877959774"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "1Sbcs9ZKr9VW",
        "colab_type": "code",
        "outputId": "d5a35b84-7aba-4af0-da8b-b765a36b158e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "cell_type": "code",
      "source": [
        "adb_engine = AdaBoostRegressor()\n",
        "adb_params = {'n_estimators' : np.arange(50, 500, 50), 'learning_rate' : [0.1, 0.2, 0.3]}\n",
        "\n",
        "adb_grid = GridSearchCV(adb_engine, adb_params, cv = 5, n_jobs = -1, verbose = 1)\n",
        "adb_grid.fit(X_train, y_train)\n",
        "print( np.sqrt( -cross_val_score(adb_grid.best_estimator_, X_train, y_train, cv = 5, scoring = \"neg_mean_squared_error\") ) )\n",
        "print( np.sqrt( mean_squared_error(y_test, adb_grid.predict(X_test)) ) )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  1.1min\n",
            "[Parallel(n_jobs=-1)]: Done 135 out of 135 | elapsed:  2.1min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0.27507794 0.28970839 0.28506227 0.29452236 0.28188844]\n",
            "0.29627741886327746\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-M7GoWdd7IRC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Bagging"
      ]
    },
    {
      "metadata": {
        "id": "H2BuCDsyDcxR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ]
    },
    {
      "metadata": {
        "id": "tnDqu1NVDgBR",
        "colab_type": "code",
        "outputId": "f805ad41-0df5-44d9-99d4-d384f98a5b3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "ranger_model = RandomForestRegressor(n_estimators = 100, oob_score = True)\n",
        "ranger_model.fit(X_train, y_train)\n",
        "print( np.sqrt( -cross_val_score(ranger_model, X_train, y_train, cv = 5, scoring = \"neg_mean_squared_error\") ) )\n",
        "np.sqrt(mean_squared_error(y_test, ranger_model.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.1813913  0.18967487 0.18195193 0.19057174 0.19058201]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1932257868916806"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "9RuZfP47orYM",
        "colab_type": "code",
        "outputId": "600ad773-164e-4d17-8d40-ca7dc897538c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "cell_type": "code",
      "source": [
        "ranger_engine = RandomForestRegressor()\n",
        "ranger_params = {'n_estimators' : np.arange(50, 500, 50)}\n",
        "\n",
        "ranger_grid = GridSearchCV(ranger_engine, ranger_params, cv = 5, n_jobs = -1, verbose = 1)\n",
        "ranger_grid.fit(X_train, y_train)\n",
        "print( np.sqrt( -cross_val_score(ranger_grid.best_estimator_, X_train, y_train, cv = 5, scoring = \"neg_mean_squared_error\") ) )\n",
        "print( np.sqrt( mean_squared_error(y_test, ranger_grid.predict(X_test)) ) )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  3.4min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0.18084762 0.18929711 0.18173912 0.18973475 0.1901538 ]\n",
            "0.19226157058661883\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Yu9osje-6XNd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Ensemble"
      ]
    },
    {
      "metadata": {
        "id": "UouYWt7h7YHo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Average ensemble"
      ]
    },
    {
      "metadata": {
        "id": "iUwVrYPgo4Gb",
        "colab_type": "code",
        "outputId": "95ea2ef4-11b2-4d4f-c74d-c2d73c6c7b2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "cell_type": "code",
      "source": [
        "# Adaboost overfitting\n",
        "outcome = pd.DataFrame( {'-actual' : np.exp(y_test) , \n",
        "               'a-xgb' :np.exp(xgb_grid.predict(X_test)),\n",
        "               'b-gbm' : np.exp(gbm_grid.predict(X_test)),\n",
        "               'c-lgbm' : np.exp(lgbm_grid.predict(X_test))\n",
        "                        } )\n",
        "# 'd-ranger' : np.exp(ranger_grid.predict(X_test)) \n",
        "outcome['avg'] = outcome.mean(axis = 1)\n",
        "outcome.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>-actual</th>\n",
              "      <th>a-xgb</th>\n",
              "      <th>b-gbm</th>\n",
              "      <th>c-lgbm</th>\n",
              "      <th>avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2137.000000</td>\n",
              "      <td>2137.000000</td>\n",
              "      <td>2137.000000</td>\n",
              "      <td>2137.000000</td>\n",
              "      <td>2137.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>9078.092653</td>\n",
              "      <td>8926.119141</td>\n",
              "      <td>8925.628689</td>\n",
              "      <td>8933.927488</td>\n",
              "      <td>8965.942939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>4566.916347</td>\n",
              "      <td>4186.385254</td>\n",
              "      <td>4234.723963</td>\n",
              "      <td>4119.665644</td>\n",
              "      <td>4201.630358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1759.000000</td>\n",
              "      <td>1943.064209</td>\n",
              "      <td>1866.598110</td>\n",
              "      <td>1866.934766</td>\n",
              "      <td>1941.154102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>5380.000000</td>\n",
              "      <td>5519.902832</td>\n",
              "      <td>5581.528634</td>\n",
              "      <td>5492.281855</td>\n",
              "      <td>5571.275555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>8330.000000</td>\n",
              "      <td>8816.053711</td>\n",
              "      <td>8882.584493</td>\n",
              "      <td>8821.118967</td>\n",
              "      <td>8866.403190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>12384.000000</td>\n",
              "      <td>11671.946289</td>\n",
              "      <td>11641.466018</td>\n",
              "      <td>11705.730757</td>\n",
              "      <td>11793.564616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>57209.000000</td>\n",
              "      <td>58919.238281</td>\n",
              "      <td>56854.062812</td>\n",
              "      <td>35158.803572</td>\n",
              "      <td>50279.161079</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            -actual         a-xgb         b-gbm        c-lgbm           avg\n",
              "count   2137.000000   2137.000000   2137.000000   2137.000000   2137.000000\n",
              "mean    9078.092653   8926.119141   8925.628689   8933.927488   8965.942939\n",
              "std     4566.916347   4186.385254   4234.723963   4119.665644   4201.630358\n",
              "min     1759.000000   1943.064209   1866.598110   1866.934766   1941.154102\n",
              "25%     5380.000000   5519.902832   5581.528634   5492.281855   5571.275555\n",
              "50%     8330.000000   8816.053711   8882.584493   8821.118967   8866.403190\n",
              "75%    12384.000000  11671.946289  11641.466018  11705.730757  11793.564616\n",
              "max    57209.000000  58919.238281  56854.062812  35158.803572  50279.161079"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "F7yvuBgChlsn",
        "colab_type": "code",
        "outputId": "297e3f17-c6d6-4e98-fdd1-31ce56709495",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# ens_predict = pd.DataFrame( { 'axgbpre' :np.exp(base_model.predict(X_test)) ,\n",
        "#                'brfpre' : np.exp(ranger.predict(X_test)) } ).mean(axis = 1)\n",
        "\n",
        "ens_predict = outcome['avg']\n",
        "\n",
        "np.sqrt( mean_squared_error(np.exp(y_test), ens_predict) )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1222.755684236997"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "vCPkcv0h_jH9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.sqrt( mean_squared_error(np.exp(y_test), ens_predict) ) - np.sqrt( mean_squared_error(y_test, np.exp(ens_predict)) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "isZUgSsMPM-l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Submit file"
      ]
    },
    {
      "metadata": {
        "id": "9VFsq7JyNVmG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#%%script false\n",
        "\n",
        "soutcome = pd.DataFrame({'a-xgb' :np.exp(xgb_grid.predict(sub)),\n",
        "               'b-gbm' : np.exp(gbm_grid.predict(sub)),\n",
        "               'c-lgbm' : np.exp(lgbm_grid.predict(sub.astype(float))) } )\n",
        "\n",
        "soutcome['avg'] = soutcome.mean(axis = 1)\n",
        "\n",
        "pd.DataFrame({ \"Price\" : soutcome['avg'] }, index = None).to_csv(\"FlightPriceEn.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "scJq7Gv5X1dC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Stacking\n",
        "\n",
        "A pipeline needed"
      ]
    },
    {
      "metadata": {
        "id": "BhvK3BQwX5Ba",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#%%script false\n",
        "\n",
        "X_stack = pd.DataFrame( {'axgbpre' :xgb_grid.predict(X_test) ,\n",
        "                         'gbm' : gbm_grid.predict(X_test),\n",
        "                         'lgbm' : lgbm_grid.predict(X_test) })\n",
        "\n",
        "y_stack = y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PQ3k-jmFZHuF",
        "colab_type": "code",
        "outputId": "2443f742-c885-4e1a-c706-963f5af65d36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "cell_type": "code",
      "source": [
        "#%%script false\n",
        "\n",
        "stack_model = xgb.XGBRegressor(learning_rate=0.05, n_estimators = 1000) #learning_rate=0.2, gamma= 0.01, max_depth = 7\n",
        "#stack_model.fit(X_stack, y_stack)\n",
        "params = {\"max_depth\" : [2, 5, 7]}\n",
        "ensemble_grid = GridSearchCV(stack_model, params, cv = 5)\n",
        "ensemble_grid.fit(X_stack, y_stack)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
              "       estimator=XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "       colsample_bytree=1, gamma=0, learning_rate=0.05, max_delta_step=0,\n",
              "       max_depth=3, min_child_weight=1, missing=None, n_estimators=1000,\n",
              "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
              "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "       silent=True, subsample=1),\n",
              "       fit_params=None, iid='warn', n_jobs=None,\n",
              "       param_grid={'max_depth': [2, 5, 7]}, pre_dispatch='2*n_jobs',\n",
              "       refit=True, return_train_score='warn', scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "MPN7YtACUoHc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#%%script false\n",
        "\n",
        "ensemble_grid.best_estimator_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yUCqKL-6S5Ty",
        "colab_type": "code",
        "outputId": "8d772f31-dae6-47a4-e26f-bc7f85baa0a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#%%script false\n",
        "\n",
        "np.sqrt( -cross_val_score(ensemble_grid, X_stack, y_stack, cv = 5, scoring = \"neg_mean_squared_error\") )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.1929779 , 0.20005908, 0.17393749, 0.19190841, 0.19283922])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "r4nkx43oW9Pc",
        "colab_type": "code",
        "outputId": "a7be3b7f-f2cf-4706-909e-8a9a3406ff7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#%%script false\n",
        "\n",
        "#column Airline_Jet Airways Business, Airline_Multiple carriers Premium economy are not available in ftest\n",
        "X_stack = pd.DataFrame( {'axgbpre' :xgb_grid.predict(X_ftest) ,\n",
        "                         'gbm' : gbm_grid.predict(X_ftest),\n",
        "                         'lgbm' : lgbm_grid.predict(X_ftest) })\n",
        "\n",
        "y_stack = y_ftest\n",
        "np.sqrt( mean_squared_error(np.exp(y_ftest), np.exp(ensemble_grid.predict(X_stack))) )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16848.24396010376"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "JWpSkl7zav8M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## KNN"
      ]
    },
    {
      "metadata": {
        "id": "JQJMhHHlazXc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6mjCnD3Z7PrS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Playground models"
      ]
    },
    {
      "metadata": {
        "id": "Nmf8OqYUpwMD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Support Vector Regression - not amazing\n",
        "Apply appropriate transformation"
      ]
    },
    {
      "metadata": {
        "id": "DQJ8BkCzpvd6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%script false\n",
        "\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.preprocessing import StandardScaler, normalize\n",
        "\n",
        "#scaler = StandardScaler()\n",
        "#svr_model = SVR(gamma = 'scale')\n",
        "\n",
        "svmpipe = Pipeline([ ( \"std\", StandardScaler() ), ( \"svm\", SVR(gamma = 'scale', kernel = 'rbf', C = 1.5, epsilon = 0.1, max_iter=-1) ) ])\n",
        "svmpipe.fit(X_train.astype(float), y_train.astype(float))\n",
        "\n",
        "np.sqrt( -cross_val_score(svmpipe, X_train.astype(float), y_train.astype(float), cv = 5, scoring = \"neg_mean_squared_error\") )\n",
        "np.sqrt( mean_squared_error(np.exp(y_test), np.exp(svmpipe.predict(X_test.astype(float)))) )\n",
        "pd.DataFrame( {'act' : np.exp(y_test) , 'axgbpre' :np.exp(svmpipe.predict(X_test.astype(float)))  } ).describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QU7-V0NvLIc_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Ridge - not a good result"
      ]
    },
    {
      "metadata": {
        "id": "XXuVEdweLH0w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%script false\n",
        "\n",
        "from sklearn.linear_model import RidgeCV\n",
        "\n",
        "ridge_model = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1], cv = 5).fit(X_train.astype(float), y_train.astype(float))\n",
        "np.sqrt( -cross_val_score(ridge_model, X_train.astype(float), y_train.astype(float), cv = 5, scoring = \"neg_mean_squared_error\") )\n",
        "np.sqrt(mean_squared_error(npa.exp(y_test.astype(float)), np.exp(ridge_model.predict(X_test.astype(float)))))\n",
        "\n",
        "pd.DataFrame( {'act' : np.exp(y_test) , \n",
        "               'axgbpre' :np.exp(base_model.predict(X_test)) ,\n",
        "               'brfpre' : np.exp(ranger.predict(X_test)),\n",
        "               'cridge' : np.exp(ridge_model.predict(X_test.astype(float))) } ).describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2lBcWgj8n_wU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### LASSO - Not a good result"
      ]
    },
    {
      "metadata": {
        "id": "5MvP-kBUn_Jv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%script false \n",
        "\n",
        "from sklearn.linear_model import LassoCV\n",
        "\n",
        "lasso_model = LassoCV(alphas=[1e-3, 1e-2, 1e-1, 1], cv = 5).fit(X_train.astype(float), y_train.astype(float))\n",
        "np.sqrt( -cross_val_score(lasso_model, X_train.astype(float), y_train.astype(float), cv = 5, scoring = \"neg_mean_squared_error\") )\n",
        "np.sqrt(mean_squared_error(np.exp(y_test.astype(float)), np.exp(lasso_model.predict(X_test.astype(float)))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B_oq1ftJL4zX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Neural Network - worst"
      ]
    },
    {
      "metadata": {
        "id": "MB9pCcl_L4OP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%script false\n",
        "\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "def baseline_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(100, input_dim=12, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dense(50, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dense(1, kernel_initializer='normal'))\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "    return model\n",
        "  \n",
        "#model.fit(X_train, y_train)\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasRegressor(build_fn=baseline_model, epochs=5, verbose = 0, validation_split = 0.20)))\n",
        "pipeline = Pipeline(estimators)\n",
        "#estimator = KerasRegressor(build_fn=baseline_model, epochs=10, batch_size=5, verbose=0)\n",
        "# np.sqrt( -cross_val_score(pipeline, X_train.astype(float), y_train.astype(float), cv = 5, scoring = \"neg_mean_squared_error\") )"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}